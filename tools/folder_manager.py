#!/usr/bin/env python3
"""
æ–‡ä»¶å¤¹ç®¡ç†å·¥å…· - ç”¨äºç»´æŠ¤debugå’Œlogsæ–‡ä»¶å¤¹
"""
import os
import sys
import shutil
import datetime
import argparse
import zipfile
from pathlib import Path
from typing import List, Dict, Tuple
import re
import glob

class FolderManager:
    """æ™ºèƒ½æ–‡ä»¶å¤¹ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str = None):
        self.project_root = Path(project_root) if project_root else Path(__file__).parent.parent
        self.logs_dir = self.project_root / "logs"
        self.debug_dir = self.project_root / "data" / "debug"
        self.archive_dir = self.project_root / "archive"
        
        # é»˜è®¤é…ç½®
        self.config = {
            'logs': {
                'max_files': 20,
                'max_size_mb': 100,
                'archive_after_days': 7,
                'compress_archive': True,
                'scan_subdirs': True  # æ–°å¢ï¼šæ‰«æå­æ–‡ä»¶å¤¹
            },
            'debug': {
                'max_files': 30,  # å‡å°‘é™åˆ¶ï¼Œå› ä¸ºç°åœ¨åˆ†æ•£åœ¨å­æ–‡ä»¶å¤¹ä¸­
                'max_size_mb': 200,
                'archive_after_days': 3,
                'compress_archive': True,
                'keep_latest_level': True,
                'scan_subdirs': True  # æ–°å¢ï¼šæ‰«æå­æ–‡ä»¶å¤¹
            }
        }
    
    def analyze_folder(self, folder_path: Path) -> Dict:
        """åˆ†ææ–‡ä»¶å¤¹çŠ¶æ€ï¼ˆé€’å½’æ‰«ææ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼‰"""
        if not folder_path.exists():
            return {'exists': False}
        
        # é€’å½’æ”¶é›†æ‰€æœ‰æ–‡ä»¶
        files = []
        for file_path in folder_path.rglob('*'):
            if file_path.is_file():
                files.append(file_path)
        
        total_size = sum(f.stat().st_size for f in files)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        files_with_time = [(f, f.stat().st_mtime) for f in files]
        files_with_time.sort(key=lambda x: x[1], reverse=True)
        
        # åˆ†ææ–‡ä»¶ç±»å‹
        file_types = {}
        for f, _ in files_with_time:
            ext = f.suffix.lower()
            file_types[ext] = file_types.get(ext, 0) + 1
        
        return {
            'exists': True,
            'total_files': len(files_with_time),
            'total_size_mb': total_size / (1024 * 1024),
            'file_types': file_types,
            'files_by_age': files_with_time,
            'oldest_file': files_with_time[-1][0] if files_with_time else None,
            'newest_file': files_with_time[0][0] if files_with_time else None
        }
    
    def cleanup_logs(self, dry_run: bool = False) -> Dict:
        """æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤¹"""
        print(f"ğŸ” åˆ†ælogsæ–‡ä»¶å¤¹: {self.logs_dir}")
        
        analysis = self.analyze_folder(self.logs_dir)
        if not analysis['exists']:
            return {'status': 'folder_not_found', 'message': 'logsæ–‡ä»¶å¤¹ä¸å­˜åœ¨'}
        
        config = self.config['logs']
        actions = []
        
        # æŒ‰ç±»å‹åˆ†ç»„æ–‡ä»¶
        game_logs = []
        error_logs = []
        other_logs = []
        
        for file_path, mtime in analysis['files_by_age']:
            filename = file_path.name
            if filename.startswith('game_'):
                game_logs.append((file_path, mtime))
            elif filename.startswith('error_'):
                error_logs.append((file_path, mtime))
            else:
                other_logs.append((file_path, mtime))
        
        # å¤„ç†æ¸¸æˆæ—¥å¿—
        if len(game_logs) > config['max_files'] // 2:
            files_to_archive = game_logs[config['max_files'] // 2:]
            for file_path, mtime in files_to_archive:
                actions.append(('archive', file_path, 'too_many_game_logs'))
        
        # å¤„ç†é”™è¯¯æ—¥å¿—
        if len(error_logs) > config['max_files'] // 2:
            files_to_archive = error_logs[config['max_files'] // 2:]
            for file_path, mtime in files_to_archive:
                actions.append(('archive', file_path, 'too_many_error_logs'))
        
        # å¤„ç†æ—§æ–‡ä»¶
        cutoff_time = datetime.datetime.now().timestamp() - (config['archive_after_days'] * 24 * 3600)
        for file_path, mtime in analysis['files_by_age']:
            if mtime < cutoff_time:
                actions.append(('archive', file_path, 'old_file'))
        
        # æ‰§è¡Œæ“ä½œ
        results = {'archived': [], 'errors': []}
        if not dry_run:
            results = self._execute_actions(actions, 'logs')
        
        return {
            'status': 'success',
            'analysis': analysis,
            'actions': actions,
            'results': results,
            'dry_run': dry_run
        }
    
    def cleanup_debug(self, dry_run: bool = False) -> Dict:
        """æ¸…ç†debugæ–‡ä»¶å¤¹"""
        print(f"ğŸ” åˆ†ædebugæ–‡ä»¶å¤¹: {self.debug_dir}")
        
        analysis = self.analyze_folder(self.debug_dir)
        if not analysis['exists']:
            return {'status': 'folder_not_found', 'message': 'debugæ–‡ä»¶å¤¹ä¸å­˜åœ¨'}
        
        config = self.config['debug']
        actions = []
        
        # åˆ†æç”Ÿæˆçš„å…³å¡æ–‡ä»¶
        level_files = {}
        other_files = []
        
        for file_path, mtime in analysis['files_by_age']:
            filename = file_path.name
            # åŒ¹é… last_generated_level_xxx.txt æ ¼å¼
            level_match = re.match(r'last_generated_level_(\d+|[\d]+)\.txt', filename)
            if level_match:
                level_id = level_match.group(1)
                if level_id not in level_files:
                    level_files[level_id] = []
                level_files[level_id].append((file_path, mtime))
            else:
                other_files.append((file_path, mtime))
        
        # ä¿ç•™æ¯ä¸ªlevelçš„æœ€æ–°æ–‡ä»¶ï¼Œå½’æ¡£å…¶ä»–çš„
        for level_id, files in level_files.items():
            if len(files) > 1:
                # æŒ‰æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„
                files.sort(key=lambda x: x[1], reverse=True)
                if config['keep_latest_level']:
                    files_to_archive = files[1:]  # ä¿ç•™æœ€æ–°çš„
                else:
                    files_to_archive = files
                
                for file_path, mtime in files_to_archive:
                    actions.append(('archive', file_path, f'duplicate_level_{level_id}'))
        
        # å¤„ç†æ–‡ä»¶æ•°é‡è¿‡å¤šçš„æƒ…å†µ
        all_debug_files = analysis['files_by_age']
        if len(all_debug_files) > config['max_files']:
            # ä¿ç•™æœ€æ–°çš„Nä¸ªæ–‡ä»¶
            files_to_archive = all_debug_files[config['max_files']:]
            for file_path, mtime in files_to_archive:
                if ('archive', file_path, f'duplicate_level_{level_id}') not in actions:
                    actions.append(('archive', file_path, 'too_many_files'))
        
        # å¤„ç†æ—§æ–‡ä»¶
        cutoff_time = datetime.datetime.now().timestamp() - (config['archive_after_days'] * 24 * 3600)
        for file_path, mtime in analysis['files_by_age']:
            if mtime < cutoff_time:
                # é¿å…é‡å¤æ·»åŠ 
                action_exists = any(action[1] == file_path for action in actions)
                if not action_exists:
                    actions.append(('archive', file_path, 'old_file'))
        
        # æ‰§è¡Œæ“ä½œ
        results = {'archived': [], 'errors': []}
        if not dry_run:
            results = self._execute_actions(actions, 'debug')
        
        return {
            'status': 'success',
            'analysis': analysis,
            'actions': actions,
            'results': results,
            'dry_run': dry_run
        }
    
    def _execute_actions(self, actions: List[Tuple], folder_type: str) -> Dict:
        """æ‰§è¡Œæ–‡ä»¶æ“ä½œ"""
        results = {'archived': [], 'errors': []}
        
        if not actions:
            return results
        
        # åˆ›å»ºå½’æ¡£ç›®å½•
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_folder = self.archive_dir / f"{folder_type}_{timestamp}"
        archive_folder.mkdir(parents=True, exist_ok=True)
        
        for action, file_path, reason in actions:
            try:
                if action == 'archive':
                    # ç§»åŠ¨æ–‡ä»¶åˆ°å½’æ¡£æ–‡ä»¶å¤¹
                    archive_path = archive_folder / file_path.name
                    shutil.move(str(file_path), str(archive_path))
                    results['archived'].append({
                        'file': file_path.name,
                        'reason': reason,
                        'archive_path': str(archive_path)
                    })
                    print(f"ğŸ“¦ å½’æ¡£: {file_path.name} -> {archive_path}")
                
            except Exception as e:
                results['errors'].append({
                    'file': file_path.name,
                    'error': str(e)
                })
                print(f"âŒ é”™è¯¯: {file_path.name} - {e}")
        
        # å‹ç¼©å½’æ¡£æ–‡ä»¶å¤¹
        if results['archived'] and self.config[folder_type]['compress_archive']:
            try:
                self._compress_archive(archive_folder)
                print(f"ğŸ—œï¸ å·²å‹ç¼©å½’æ¡£: {archive_folder.name}.zip")
            except Exception as e:
                print(f"âŒ å‹ç¼©å¤±è´¥: {e}")
        
        return results
    
    def _compress_archive(self, archive_folder: Path):
        """å‹ç¼©å½’æ¡£æ–‡ä»¶å¤¹"""
        zip_path = archive_folder.with_suffix('.zip')
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in archive_folder.rglob('*'):
                if file_path.is_file():
                    arcname = file_path.relative_to(archive_folder)
                    zipf.write(file_path, arcname)
        
        # åˆ é™¤åŸæ–‡ä»¶å¤¹
        shutil.rmtree(archive_folder)
    
    def create_folder_structure(self):
        """åˆ›å»ºä¼˜åŒ–çš„æ–‡ä»¶å¤¹ç»“æ„"""
        folders_to_create = [
            self.logs_dir,
            self.debug_dir,
            self.archive_dir,
            self.logs_dir / "session",
            self.logs_dir / "error", 
            self.logs_dir / "performance",
            self.debug_dir / "levels",
            self.debug_dir / "maps",
            self.debug_dir / "entities"
        ]
        
        for folder in folders_to_create:
            folder.mkdir(parents=True, exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºæ–‡ä»¶å¤¹: {folder}")
    
    def get_status_report(self) -> Dict:
        """è·å–æ–‡ä»¶å¤¹çŠ¶æ€æŠ¥å‘Š"""
        logs_analysis = self.analyze_folder(self.logs_dir)
        debug_analysis = self.analyze_folder(self.debug_dir)
        
        return {
            'logs': logs_analysis,
            'debug': debug_analysis,
            'recommendations': self._get_recommendations(logs_analysis, debug_analysis)
        }
    
    def _get_recommendations(self, logs_analysis: Dict, debug_analysis: Dict) -> List[str]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if logs_analysis.get('total_files', 0) > self.config['logs']['max_files']:
            recommendations.append(f"æ—¥å¿—æ–‡ä»¶è¿‡å¤š ({logs_analysis['total_files']}ä¸ª)ï¼Œå»ºè®®æ¸…ç†")
        
        if debug_analysis.get('total_files', 0) > self.config['debug']['max_files']:
            recommendations.append(f"Debugæ–‡ä»¶è¿‡å¤š ({debug_analysis['total_files']}ä¸ª)ï¼Œå»ºè®®æ¸…ç†")
        
        if logs_analysis.get('total_size_mb', 0) > self.config['logs']['max_size_mb']:
            recommendations.append(f"æ—¥å¿—æ–‡ä»¶å¤¹è¿‡å¤§ ({logs_analysis['total_size_mb']:.1f}MB)")
        
        if debug_analysis.get('total_size_mb', 0) > self.config['debug']['max_size_mb']:
            recommendations.append(f"Debugæ–‡ä»¶å¤¹è¿‡å¤§ ({debug_analysis['total_size_mb']:.1f}MB)")
        
        return recommendations


def main():
    parser = argparse.ArgumentParser(description='æ–‡ä»¶å¤¹ç®¡ç†å·¥å…·')
    parser.add_argument('--cleanup-logs', action='store_true', help='æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤¹')
    parser.add_argument('--cleanup-debug', action='store_true', help='æ¸…ç†debugæ–‡ä»¶å¤¹')
    parser.add_argument('--cleanup-all', action='store_true', help='æ¸…ç†æ‰€æœ‰æ–‡ä»¶å¤¹')
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºæ–‡ä»¶å¤¹çŠ¶æ€')
    parser.add_argument('--dry-run', action='store_true', help='æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ‰§è¡Œæ“ä½œ')
    parser.add_argument('--create-structure', action='store_true', help='åˆ›å»ºä¼˜åŒ–çš„æ–‡ä»¶å¤¹ç»“æ„')
    
    args = parser.parse_args()
    
    manager = FolderManager()
    
    if args.create_structure:
        manager.create_folder_structure()
        return
    
    if args.status:
        print("ğŸ“Š æ–‡ä»¶å¤¹çŠ¶æ€æŠ¥å‘Š")
        print("=" * 50)
        report = manager.get_status_report()
        
        # æ—¥å¿—æ–‡ä»¶å¤¹çŠ¶æ€
        logs = report['logs']
        if logs['exists']:
            print(f"ğŸ“ Logsæ–‡ä»¶å¤¹:")
            print(f"   æ–‡ä»¶æ•°é‡: {logs['total_files']}")
            print(f"   æ€»å¤§å°: {logs['total_size_mb']:.1f} MB")
            print(f"   æ–‡ä»¶ç±»å‹: {logs['file_types']}")
        else:
            print("ğŸ“ Logsæ–‡ä»¶å¤¹: ä¸å­˜åœ¨")
        
        print()
        
        # Debugæ–‡ä»¶å¤¹çŠ¶æ€
        debug = report['debug']
        if debug['exists']:
            print(f"ğŸ› Debugæ–‡ä»¶å¤¹:")
            print(f"   æ–‡ä»¶æ•°é‡: {debug['total_files']}")
            print(f"   æ€»å¤§å°: {debug['total_size_mb']:.1f} MB")
            print(f"   æ–‡ä»¶ç±»å‹: {debug['file_types']}")
        else:
            print("ğŸ› Debugæ–‡ä»¶å¤¹: ä¸å­˜åœ¨")
        
        print()
        
        # å»ºè®®
        if report['recommendations']:
            print("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for rec in report['recommendations']:
                print(f"   â€¢ {rec}")
        else:
            print("âœ… æ–‡ä»¶å¤¹çŠ¶æ€è‰¯å¥½")
        
        return
    
    if args.cleanup_logs or args.cleanup_all:
        print("ğŸ§¹ æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤¹...")
        result = manager.cleanup_logs(dry_run=args.dry_run)
        print(f"ç»“æœ: {result['status']}")
        if result.get('actions'):
            print(f"è®¡åˆ’æ“ä½œ: {len(result['actions'])}ä¸ªæ–‡ä»¶")
        print()
    
    if args.cleanup_debug or args.cleanup_all:
        print("ğŸ§¹ æ¸…ç†debugæ–‡ä»¶å¤¹...")
        result = manager.cleanup_debug(dry_run=args.dry_run)
        print(f"ç»“æœ: {result['status']}")
        if result.get('actions'):
            print(f"è®¡åˆ’æ“ä½œ: {len(result['actions'])}ä¸ªæ–‡ä»¶")
        print()
    
    if not any([args.cleanup_logs, args.cleanup_debug, args.cleanup_all, args.status, args.create_structure]):
        parser.print_help()


if __name__ == "__main__":
    main()